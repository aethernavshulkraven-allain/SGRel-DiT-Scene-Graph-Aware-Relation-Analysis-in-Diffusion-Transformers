{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "783644da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch \n",
    "import numpy as np\n",
    "import einops   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0768d8a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/home/namanb/SBILab/CSE677/Project/SGRel-DiT-Scene-Graph-Aware-Relation-Analysis-in-Diffusion-Transformers/relation-analysis/outputs/stage_a/vg_stage_a_full.jsonl\", \"r\") as f:\n",
    "    data = [json.loads(line) for line in f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "54d61967",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1342859"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c21805de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1342859 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1342859/1342859 [00:00<00:00, 1724304.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#unique predicates\n",
    "from tqdm import tqdm\n",
    "predicates = set()\n",
    "for item in tqdm(data):\n",
    "    # print(item)\n",
    "    predicates.add(item[\"triple\"][\"predicate\"])\n",
    "print(len(predicates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a54e421",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'triple': {'subject': 'shade',\n",
       "  'predicate': 'on',\n",
       "  'object': 'sidewalk',\n",
       "  'relation_type': 'geometric',\n",
       "  'source_image_id': 1,\n",
       "  'source_relationship_id': 15927},\n",
       " 'prompt': 'a photo of shade on sidewalk on a plain background',\n",
       " 'concepts': ['shade', 'on', 'sidewalk'],\n",
       " 'template_id': 'simple_v1'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d6c30d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2d6fe52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Counting predicates: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1342859/1342859 [00:01<00:00, 1193031.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicate distribution:\n",
      "on                  : 668005 samples\n",
      "in                  : 231977 samples\n",
      "wearing             : 140590 samples\n",
      "around/near         :  67126 samples\n",
      "above               :  54393 samples\n",
      "behind              :  40452 samples\n",
      "holding             :  37909 samples\n",
      "below               :  23187 samples\n",
      "sitting on          :  13893 samples\n",
      "hanging from        :  13810 samples\n",
      "in front of         :  13367 samples\n",
      "standing on         :   7647 samples\n",
      "riding              :   7580 samples\n",
      "looking at          :   6541 samples\n",
      "carrying            :   4799 samples\n",
      "eating              :   4507 samples\n",
      "using               :   1759 samples\n",
      "pulling             :   1178 samples\n",
      "touching            :   1133 samples\n",
      "playing with        :    914 samples\n",
      "drinking            :    647 samples\n",
      "left of             :    614 samples\n",
      "pushing             :    430 samples\n",
      "right of            :    401 samples\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get all predicates and their counts\n",
    "predicate_counts = {}\n",
    "for item in tqdm(data, desc=\"Counting predicates\"):\n",
    "    pred = item[\"triple\"][\"predicate\"]\n",
    "    predicate_counts[pred] = predicate_counts.get(pred, 0) + 1\n",
    "\n",
    "# Sort by count\n",
    "sorted_predicates = sorted(predicate_counts.items(), key=lambda x: x[1], reverse=True)\n",
    "print(\"\\nPredicate distribution:\")\n",
    "for pred, count in sorted_predicates:\n",
    "    print(f\"{pred:20s}: {count:6d} samples\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc720d2",
   "metadata": {},
   "source": [
    "# Dataset Generation Scripts Created\n",
    "\n",
    "I've created a complete multi-GPU pipeline for generating saliency map datasets. Here's what's available:\n",
    "\n",
    "## ðŸ“ Files Created\n",
    "\n",
    "1. **`generate_saliency_dataset.py`** - Main generation script\n",
    "   - Uses 4 GPUs in parallel\n",
    "   - Generates 2000 samples per relationship class\n",
    "   - Creates 3 separate datasets (early/middle/late layers)\n",
    "\n",
    "2. **`dataset_loader.py`** - PyTorch Dataset class and utilities\n",
    "   - Load datasets for training\n",
    "   - Verify dataset integrity\n",
    "   - View statistics and samples\n",
    "\n",
    "3. **`test_setup.py`** - Pre-flight test script\n",
    "   - Verifies everything works before full generation\n",
    "   - Tests pipeline, data loading, and save/load\n",
    "\n",
    "4. **`DATASET_README.md`** - Complete documentation\n",
    "\n",
    "## ðŸš€ Quick Start\n",
    "\n",
    "### Step 1: Test the setup (RECOMMENDED)\n",
    "```bash\n",
    "cd /home/namanb/SBILab/CSE677/Project/SGRel-DiT-Scene-Graph-Aware-Relation-Analysis-in-Diffusion-Transformers\n",
    "python test_setup.py\n",
    "```\n",
    "\n",
    "### Step 2: Generate all datasets\n",
    "```bash\n",
    "python generate_saliency_dataset.py --layer-config all --num-gpus 4\n",
    "```\n",
    "\n",
    "This will create:\n",
    "```\n",
    "saliency_datasets/\n",
    "â”œâ”€â”€ early_layers/    # Layers 0-6\n",
    "â”œâ”€â”€ middle_layers/   # Layers 7-12\n",
    "â””â”€â”€ late_layers/     # Layers 13-18\n",
    "```\n",
    "\n",
    "## ðŸ“Š Dataset Details\n",
    "\n",
    "- **24 relationship classes** (on, in, wearing, holding, etc.)\n",
    "- **2000 samples per class** = 48,000 samples per dataset\n",
    "- **3 datasets total** = 144,000 samples\n",
    "- **512x512 images** â†’ 32x32 saliency maps\n",
    "- **Multi-GPU**: 500 samples per GPU (parallel processing)\n",
    "\n",
    "## â±ï¸ Estimated Time\n",
    "\n",
    "With 4 GPUs (assuming ~3-5 sec/sample):\n",
    "- Per class: ~40-60 minutes\n",
    "- Per dataset: ~16-24 hours\n",
    "- All 3 datasets: ~48-72 hours\n",
    "\n",
    "## ðŸ’¾ Storage\n",
    "\n",
    "- ~150-250MB per 1000 samples\n",
    "- Total: ~30-50GB for all 3 datasets\n",
    "\n",
    "## ðŸ”§ Advanced Usage\n",
    "\n",
    "### Generate only one dataset\n",
    "```bash\n",
    "python generate_saliency_dataset.py --layer-config early_layers\n",
    "```\n",
    "\n",
    "### Use fewer GPUs\n",
    "```bash\n",
    "python generate_saliency_dataset.py --num-gpus 2\n",
    "```\n",
    "\n",
    "### Custom sample count\n",
    "```bash\n",
    "python generate_saliency_dataset.py --samples-per-class 1000\n",
    "```\n",
    "\n",
    "### Verify generated dataset\n",
    "```bash\n",
    "python dataset_loader.py --dataset-path saliency_datasets/early_layers --action verify\n",
    "```\n",
    "\n",
    "## ðŸ“ˆ Using in Training\n",
    "\n",
    "```python\n",
    "from dataset_loader import SaliencyMapDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "dataset = SaliencyMapDataset(\"saliency_datasets/early_layers\")\n",
    "loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "for batch in loader:\n",
    "    saliency = batch[\"saliency_maps\"]  # (B, 3, 32, 32)\n",
    "    labels = batch[\"label\"]            # (B,)\n",
    "    # Train your classifier...\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cse677",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
